{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Stock Level Recommendation System Summary\n",
        "##Objective:\n",
        "To optimize stock levels for each vending machine and product based on sales trends, current stock levels, restocking frequencies, and logistics constraints, while ensuring minimum stockouts and avoiding overstocking. This system will assist AGPG in becoming more competitive by making more accurate, data-driven decisions for product orders and restocking.\n",
        "\n",
        "##Workflow Overview:\n",
        "###1. Data Preparation\n",
        "Data Source: The dataset contains sales transactions with key attributes like *Machine ID, Product Name, Location Type, Date, Units Sold, Current Stock Level, Lead Time, etc.*\n",
        "Purpose: This dataset allows us to track sales per product per vending machine over time, enabling precise stock-level calculations for future restocks.\n",
        "###2. Calculate Average Daily Sales\n",
        "For Each Machine and Product:\n",
        "Total Units Sold: Calculate the total units sold per product across a given period.\n",
        "Active Days: Count the number of unique active days for each product (days when it was sold).\n",
        "\n",
        "Avg_Daily_Sales = *Total_Units_Sold / Active_Days*\n",
        "\n",
        "  This gives us an accurate picture of daily sales rates.\n",
        "###3. Merge Operational Factors\n",
        "Lead Time: The number of days required to restock. This is calculated per machine and product combination based on historical supply chain data.\n",
        "Restock Frequency: For example, restock might occur every 5 days depending on machine demand.\n",
        "\n",
        "Restock_Frequency_Days = *12 / Avg_Daily_Sales*\n",
        "\n",
        "  This ensures that products are ordered at a frequency based on actual sales trends, balancing stock availability and shelf space.\n",
        "###4. Apply Safety Stock Buffer\n",
        "Safety Stock: A 20% buffer (or a dynamic percentage based on sales volatility) is applied to the recommended stock level to prevent stockouts during demand surges or supply chain delays.\n",
        "\n",
        "*Safety_Stock = Avg_Daily_Sales × 0.2*\n",
        "###5. Final Recommended Stock Level Formula\n",
        "\n",
        "Recommended_Stock_Level = *(Avg_Daily_Sales × (Restock_Frequency_Days + Lead_Time_Days)) + Safety_Stock* <br>\n",
        "\n",
        "Purpose: This formula ensures sufficient stock to meet demand until the next restocking, accounting for both the lead time and safety stock buffer.\n",
        "Output & Visualization\n",
        "###6. Grouped Results\n",
        "Results show the Recommended Stock Levels per:\n",
        "Machine ID: Unique identifier for each vending machine.\n",
        "Location Type: For example, busy locations like Changi Airport or quieter locations like East Coast Park.\n",
        "Product Name: Different product categories like soft drinks, juices, etc.\n",
        "###7. Visualizations\n",
        "Bar Charts for Each Machine: Each machine will have a bar chart showing the recommended stock levels per product.\n",
        "Value Labels: Each bar will display the recommended order quantity.\n",
        "Order Table: A detailed order table showing the current stock, recommended stock, and order quantity for each product in each machine.\n",
        "Restock Date: The projected next restock date for each machine will be displayed based on the calculated restocking frequency."
      ],
      "metadata": {
        "id": "bQRow1NSaJvI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qZuYQHSSRdMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d962d46-a3c1-45e1-fa03-bec0da6e6f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Import relevant libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "GYLTrbHkc-sh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the data\n",
        "The data includes 15 types of popular drinks sold in vending machines in Singapore, and are sold at 5 different vending machines at different locations across the country."
      ],
      "metadata": {
        "id": "ZBqRfAq1gecF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create pandas dataframe from CSV\n",
        "\n",
        "drinks = pd.read_csv('/content/drive/My Drive/DBTT GROUP 1/Analytics/Vending_Machine_Sales_Data_Singapore.csv')\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', 1000)\n",
        "print(drinks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "rkBBCKIJSn_g",
        "outputId": "ff1f8888-a13b-4e4a-8faf-7856a4dbd9c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/My Drive/DBTT GROUP 1/Analytics/Vending_Machine_Sales_Data_Singapore.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-57ffaaacfed5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Create pandas dataframe from CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdrinks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/DBTT GROUP 1/Analytics/Vending_Machine_Sales_Data_Singapore.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.width'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/DBTT GROUP 1/Analytics/Vending_Machine_Sales_Data_Singapore.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Describe the data\n",
        "drinks.describe(include='all')"
      ],
      "metadata": {
        "id": "q_7PQzn9TodX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "7741aa2e-634a-41ac-92fa-f39ea807d8b0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'drinks' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-aa160a860e58>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Describe the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrinks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'drinks' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# STEP 1: Total units sold per Machine + Product + Location\n",
        "total_sales = drinks.groupby(['Machine_ID', 'Location_Type', 'Product_ID', 'Product_Name'])['Units_Sold'].sum().reset_index()\n",
        "total_sales.rename(columns={'Units_Sold': 'Total_Units_Sold'}, inplace=True)\n",
        "\n",
        "# STEP 2: Count unique active days per Machine + Product + Location\n",
        "active_days = drinks.groupby(['Machine_ID', 'Location_Type', 'Product_ID'])['Date'].nunique().reset_index()\n",
        "active_days.rename(columns={'Date': 'Active_Days'}, inplace=True)\n",
        "\n",
        "# STEP 3: Merge total_sales and active_days on all relevant keys\n",
        "sales_data = total_sales.merge(active_days, on=['Machine_ID', 'Location_Type', 'Product_ID'])\n",
        "\n",
        "# STEP 4: Calculate Average Daily Sales\n",
        "sales_data['Avg_Daily_Sales'] = (sales_data['Total_Units_Sold'] / sales_data['Active_Days']).round(2)\n",
        "\n",
        "# STEP 5: Merge average Lead Time (machine + product level)\n",
        "lead_time = drinks.groupby(['Machine_ID', 'Location_Type', 'Product_ID'])['Lead_Time_Days'].mean().reset_index()\n",
        "sales_data = sales_data.merge(lead_time, on=['Machine_ID', 'Location_Type', 'Product_ID'])\n",
        "\n",
        "# STEP 6: Dynamic Restock Frequency based on activity\n",
        "sales_data['Restock_Frequency_Days'] = (12 / sales_data['Avg_Daily_Sales']).round().clip(lower=2, upper=10)\n",
        "\n",
        "# STEP 7: Calculate Safety Stock (20% buffer)\n",
        "sales_data['Safety_Stock'] = (sales_data['Avg_Daily_Sales'] * 0.2).round()\n",
        "\n",
        "# STEP 8: Calculate Recommended Stock Level\n",
        "sales_data['Recommended_Stock_Level'] = (\n",
        "    sales_data['Avg_Daily_Sales'] * (sales_data['Restock_Frequency_Days'] + sales_data['Lead_Time_Days'])\n",
        "    + sales_data['Safety_Stock']\n",
        ").round()\n",
        "\n",
        "# Merge Category info from drinks dataframe\n",
        "category_lookup = drinks[['Product_ID', 'Category']].drop_duplicates()\n",
        "sales_data = sales_data.merge(category_lookup, on='Product_ID', how='left')\n",
        "\n",
        "\n",
        "# STEP 9: Final Output\n",
        "sales_data = sales_data[['Machine_ID', 'Location_Type','Product_ID','Product_Name', 'Category',\n",
        "                         'Avg_Daily_Sales', 'Lead_Time_Days',\n",
        "                         'Restock_Frequency_Days', 'Recommended_Stock_Level']]\n",
        "print(sales_data.head(50))\n"
      ],
      "metadata": {
        "id": "K2J1wCYydn45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_data.head(100)"
      ],
      "metadata": {
        "id": "nCRx6VLvXeq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, row in machine_summary.iterrows():\n",
        "    machine_id = row['Machine_ID']\n",
        "    location = row['Location_Type']\n",
        "    rec_stock = row['Recommended_Stock_Level']\n",
        "    threshold = 0.8 * rec_stock\n",
        "\n",
        "    df_machine = daily_sales[daily_sales['Machine_ID'] == machine_id].sort_values('Date').copy()\n",
        "\n",
        "    stock_level = []\n",
        "    current_stock = rec_stock\n",
        "    restock_dates = []\n",
        "\n",
        "    for _, r in df_machine.iterrows():\n",
        "        current_stock -= r['Units_Sold']\n",
        "        if current_stock <= rec_stock - threshold:\n",
        "            restock_dates.append(r['Date'])\n",
        "            current_stock = rec_stock\n",
        "        stock_level.append(current_stock)\n",
        "\n",
        "    df_machine['Simulated_Stock'] = stock_level\n",
        "\n",
        "    # Plot with annotations\n",
        "    plt.figure(figsize=(12,6))\n",
        "    plt.plot(df_machine['Date'], df_machine['Simulated_Stock'], label=f'Stock Level - {location}')\n",
        "\n",
        "    # Recommended stock level line\n",
        "    plt.axhline(y=rec_stock, color='blue', linestyle='--', label=f'Recommended Stock Level ({int(rec_stock)} units)')\n",
        "\n",
        "    # Horizontal shaded region below threshold\n",
        "    plt.axhspan(0, rec_stock - threshold, color='red', alpha=0.1, label='Below Threshold Zone')\n",
        "\n",
        "    # Annotate threshold value\n",
        "    plt.text(df_machine['Date'].min(), rec_stock - threshold + 10,\n",
        "             f'Threshold = {int(rec_stock - threshold)} units',\n",
        "             color='red', fontsize=9, va='bottom', ha='left')\n",
        "\n",
        "    # Restock markers with date labels\n",
        "    for restock_date in restock_dates:\n",
        "        plt.axvline(x=restock_date, color='green', linestyle='--')\n",
        "        plt.text(restock_date, (rec_stock - threshold) / 2, restock_date.strftime('%b %d'),\n",
        "                 color='green', rotation=0, verticalalignment='bottom', fontsize=8)\n",
        "\n",
        "    plt.title(f\"Stock Level for {machine_id} - {location}\")\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Stock Level (Units)')\n",
        "    plt.ylim(0, rec_stock * 1.2)\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "VeSuM9SRrkcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for _, row in machines.iterrows():\n",
        "    machine_id = row['Machine_ID']\n",
        "    location = row['Location_Type']\n",
        "\n",
        "    subset = sales_data[sales_data['Machine_ID'] == machine_id].sort_values('Recommended_Stock_Level', ascending=False)\n",
        "    total_capacity = subset['Recommended_Stock_Level'].sum()\n",
        "\n",
        "    plt.figure(figsize=(10,6))\n",
        "    sns.barplot(\n",
        "        data=subset,\n",
        "        x='Product_Name',\n",
        "        y='Recommended_Stock_Level',\n",
        "        palette='Set3',\n",
        "\n",
        "    )\n",
        "\n",
        "    for p in plt.gca().patches:\n",
        "        plt.gca().annotate(\n",
        "            f'{int(p.get_height())}',\n",
        "            (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "            ha='center', va='bottom', fontsize=9\n",
        "        )\n",
        "\n",
        "    plt.title(f\"Restock Recommendations for {machine_id} - {location}\\nTotal Capacity: {int(total_capacity)} units\", fontsize=12)\n",
        "    plt.xlabel('Product Name')\n",
        "    plt.ylabel('Recommended Stock Level')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "GQMXJlBfXqIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datetime import timedelta\n",
        "\n",
        "order_tables = []  # To store all machine-level dataframes\n",
        "\n",
        "for _, row in machine_summary.iterrows():\n",
        "    machine_id = row['Machine_ID']\n",
        "    location = row['Location_Type']\n",
        "\n",
        "    # Grab product-level recommendations\n",
        "    machine_subset = sales_data[sales_data['Machine_ID'] == machine_id][['Product_Name', 'Product_ID', 'Category', 'Recommended_Stock_Level']].copy()\n",
        "\n",
        "    # Get the latest CURRENT stock level from drinks dataset and round to whole numbers\n",
        "    latest_stock = drinks[drinks['Machine_ID'] == machine_id].groupby('Product_ID')['Current_Stock_Level'].mean().reset_index()\n",
        "    latest_stock['Current_Stock_Level'] = latest_stock['Current_Stock_Level'].round().astype(int)  # Round to whole number\n",
        "\n",
        "    # Merge with recommended stock\n",
        "    machine_subset = machine_subset.merge(latest_stock, on='Product_ID', how='left')\n",
        "\n",
        "    # Calculate actual top-up requirement (ensure it's a whole number)\n",
        "    machine_subset['Order_Quantity (Units)'] = (machine_subset['Recommended_Stock_Level'] - machine_subset['Current_Stock_Level']).clip(lower=0).round().astype(int)\n",
        "\n",
        "    # Reformat table with additional columns\n",
        "    machine_subset = machine_subset[['Product_Name', 'Category', 'Current_Stock_Level', 'Recommended_Stock_Level', 'Order_Quantity (Units)']]\n",
        "    machine_subset = machine_subset.sort_values('Order_Quantity (Units)', ascending=False).reset_index(drop=True)\n",
        "\n",
        "    # Calculate next restock date based on average restock frequency\n",
        "    last_sale_date = daily_sales[daily_sales['Machine_ID'] == machine_id]['Date'].max()\n",
        "    next_restock_date = last_sale_date + timedelta(days=int(row['Avg_Restock_Frequency_Days']))\n",
        "\n",
        "    # Add machine, location, and next restock date\n",
        "    machine_subset.insert(0, 'Machine_ID', machine_id)\n",
        "    machine_subset.insert(1, 'Location', location)\n",
        "    machine_subset.insert(2, 'Next_Restock_Date', next_restock_date.strftime('%Y-%m-%d'))\n",
        "\n",
        "    # Append to global list\n",
        "    order_tables.append(machine_subset)\n",
        "\n",
        "# Combine all tables into one dataframe\n",
        "final_order_df = pd.concat(order_tables, ignore_index=True)\n",
        "final_order_df\n"
      ],
      "metadata": {
        "id": "akmEzRpgjaEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "# Define the cutoff date for the last 3 months\n",
        "cutoff_date = daily_sales['Date'].max() - datetime.timedelta(days=90)\n",
        "\n",
        "for idx, row in machine_summary.iterrows():\n",
        "    machine_id = row['Machine_ID']\n",
        "    location = row['Location_Type']\n",
        "    rec_stock = row['Recommended_Stock_Level']\n",
        "    threshold = 0.8 * rec_stock\n",
        "\n",
        "    df_machine = daily_sales[(daily_sales['Machine_ID'] == machine_id) &\n",
        "                             (daily_sales['Date'] >= cutoff_date)].sort_values('Date').copy()\n",
        "\n",
        "    stock_level = []\n",
        "    current_stock = rec_stock\n",
        "    restock_dates = []\n",
        "\n",
        "    for _, r in df_machine.iterrows():\n",
        "        current_stock -= r['Units_Sold']\n",
        "        if current_stock <= rec_stock - threshold:\n",
        "            restock_dates.append(r['Date'])\n",
        "            current_stock = rec_stock\n",
        "        stock_level.append(current_stock)\n",
        "\n",
        "    df_machine['Simulated_Stock'] = stock_level\n",
        "\n",
        "    # Plot with reduced width\n",
        "    plt.figure(figsize=(8, 4))  # Adjusted figure size for a more compact graph\n",
        "    plt.plot(df_machine['Date'], df_machine['Simulated_Stock'], label=f'Stock Level - {location}')\n",
        "\n",
        "    # Recommended stock level line\n",
        "    plt.axhline(y=rec_stock, color='blue', linestyle='--', label=f'Recommended Stock Level ({int(rec_stock)} units)')\n",
        "\n",
        "    # Horizontal shaded region below threshold\n",
        "    plt.axhspan(0, rec_stock - threshold, color='red', alpha=0.1, label='Below Threshold Zone')\n",
        "\n",
        "    # Annotate threshold value\n",
        "    plt.text(df_machine['Date'].min(), rec_stock - threshold + 10,\n",
        "             f'Threshold = {int(rec_stock - threshold)} units',\n",
        "             color='red', fontsize=9, va='bottom', ha='left')\n",
        "\n",
        "    # Restock markers with date labels\n",
        "    for restock_date in restock_dates:\n",
        "        plt.axvline(x=restock_date, color='green', linestyle='--')\n",
        "        plt.text(restock_date, (rec_stock - threshold) / 2, restock_date.strftime('%b %d'),\n",
        "                 color='green', rotation=0, verticalalignment='bottom', fontsize=8)\n",
        "\n",
        "    plt.title(f\"Stock Level for {machine_id} - {location}\")\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('Stock Level (Units)')\n",
        "    plt.ylim(0, rec_stock * 1.2)\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=30, ha='right')\n",
        "    plt.grid(True, linestyle='--', alpha=0.5)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "PSpGolLcQzh3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}